{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from hypnettorch.data import FashionMNISTData, MNISTData\n",
    "from hypnettorch.data.special.split_mnist import get_split_mnist_handlers\n",
    "from hypnettorch.data.special.split_cifar import get_split_cifar_handlers\n",
    "from hypnettorch.mnets import LeNet, ResNet\n",
    "from hypnettorch.hnets import HMLP, StructuredHMLP, ChunkedHMLP\n",
    "\n",
    "from utils.data import get_mnist_data_loaders, get_emnist_data_loaders, randomize_targets, select_from_classes\n",
    "from utils.visualization import show_imgs, get_model_dot\n",
    "from utils.others import measure_alloc_mem, count_parameters\n",
    "from utils.timing import func_timer\n",
    "from utils.metrics import get_accuracy\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "torch.set_printoptions(precision=3, linewidth=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"epochs\": 2,\n",
    "    \"max_minibatches_per_epoch\": 600,\n",
    "    \"data\": {\n",
    "        \"name\": \"mnist|fmnist\",\n",
    "        \"batch_size\": 32,\n",
    "        \"data_dir\": \"data_tmp\",\n",
    "        \"num_tasks\": 5, # only for split tasks\n",
    "        \"num_classes_per_task\": 2, # only for split tasks\n",
    "        \"validation_size\": 960,\n",
    "    },\n",
    "    \"solver\": {\n",
    "        \"use\": \"resnet\",\n",
    "        \"lenet\": {\n",
    "            \"arch\": \"mnist_large\",\n",
    "            \"num_classes\": 10,\n",
    "            \"no_weights\": True,\n",
    "        },\n",
    "        \"resnet\": {\n",
    "            \"n\": 5,\n",
    "            \"k\": 1,\n",
    "            \"use_bias\": True,\n",
    "            \"num_classes\": 10,\n",
    "            \"no_weights\": True,\n",
    "        },\n",
    "    },\n",
    "    \"hnet\": {\n",
    "        \"lr\": 1e-3,\n",
    "        \"reg_lr\": 1e-3,\n",
    "        \"model\": {\n",
    "            \"layers\": [128, 128],  \n",
    "        },\n",
    "        \"chunk_emb_size\": 16,\n",
    "        \"chunk_size\": 3500,\n",
    "        \"cond_in_size\": 32,\n",
    "        \"num_cond_embs\": 4,\n",
    "        \"cond_chunk_embs\": True,\n",
    "        \"reg_beta\": 0.03,\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # \"device\": \"cpu\",\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "if config[\"data\"][\"name\"] == \"mnist|fmnist\":\n",
    "    mnist = MNISTData(config[\"data\"][\"data_dir\"], use_one_hot=True, validation_size=config[\"data\"][\"validation_size\"])\n",
    "    fmnist = FashionMNISTData(config[\"data\"][\"data_dir\"], use_one_hot=True, validation_size=config[\"data\"][\"validation_size\"])\n",
    "elif config[\"data\"][\"name\"] == \"splitmnist\":\n",
    "    dhandlers = get_split_mnist_handlers(config[\"data\"][\"data_dir\"], use_one_hot=True, num_tasks=config[\"data\"][\"num_tasks\"], num_classes_per_task=config[\"data\"][\"num_classes_per_task\"], validation_size=config[\"data\"][\"validation_size\"])\n",
    "elif config[\"data\"][\"name\"] == \"splitcifar\":\n",
    "    dhandlers = get_split_mnist_handlers(config[\"data\"][\"data_dir\"], use_one_hot=True, num_tasks=config[\"data\"][\"num_tasks\"], num_classes_per_task=config[\"data\"][\"num_classes_per_task\"], validation_size=config[\"data\"][\"validation_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "# target networks (solvers)\n",
    "if config[\"solver\"][\"use\"] == \"lenet\":\n",
    "    solver_child = LeNet(in_shape=mnist.in_shape, **config[\"solver\"][\"lenet\"]).to(config[\"device\"])\n",
    "    solver_root = LeNet(in_shape=mnist.in_shape, **config[\"solver\"][\"lenet\"]).to(config[\"device\"])\n",
    "elif config[\"solver\"][\"use\"] == \"resnet\":\n",
    "    solver_child = ResNet(in_shape=mnist.in_shape, **config[\"solver\"][\"resnet\"]).to(config[\"device\"])\n",
    "    solver_root = ResNet(in_shape=mnist.in_shape, **config[\"solver\"][\"resnet\"]).to(config[\"device\"])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown solver: {config['solver']['use']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hnet = StructuredHMLP(\n",
    "#     solver.param_shapes,\n",
    "#     chunk_shapes=[[[16]], [[32]], [[64]], [[16, 16, 3, 3], [16]], [[32, 32, 3, 3], [32]], [[64, 64, 3, 3], [64]], [[10, 64], [10]]],\n",
    "#     num_per_chunk=[14, 12, 12, 6, 5, 5, 1],\n",
    "#     chunk_emb_sizes=32,\n",
    "#     hmlp_kwargs=config[\"hnet\"][\"model\"],\n",
    "#     assembly_fct=assembly_fct,\n",
    "#     uncond_in_size=0, cond_in_size=8, num_cond_embs=2).to(config[\"device\"]\n",
    "# )\n",
    "# \"\"\"\n",
    "# missing in chunk_shapes:\n",
    "# [16, 1, 3, 3] [16]\n",
    "# [32, 16, 3, 3] [32]\n",
    "# [64, 32, 3, 3] [64]\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "hnet_child = ChunkedHMLP(\n",
    "    solver_child.param_shapes,\n",
    "    layers=config[\"hnet\"][\"model\"][\"layers\"],\n",
    "    chunk_size=config[\"hnet\"][\"chunk_size\"],\n",
    "    chunk_emb_size=config[\"hnet\"][\"chunk_emb_size\"],\n",
    "    cond_chunk_embs=config[\"hnet\"][\"cond_chunk_embs\"],\n",
    "    cond_in_size=config[\"hnet\"][\"cond_in_size\"],\n",
    "    num_cond_embs=config[\"hnet\"][\"num_cond_embs\"],\n",
    "    no_uncond_weights=True,\n",
    "    no_cond_weights=False,\n",
    ").to(config[\"device\"])\n",
    "\n",
    "hnet_root = ChunkedHMLP(\n",
    "    hnet_child.unconditional_param_shapes,\n",
    "    layers=config[\"hnet\"][\"model\"][\"layers\"],\n",
    "    chunk_size=config[\"hnet\"][\"chunk_size\"],\n",
    "    chunk_emb_size=config[\"hnet\"][\"chunk_emb_size\"],\n",
    "    cond_chunk_embs=config[\"hnet\"][\"cond_chunk_embs\"],\n",
    "    cond_in_size=config[\"hnet\"][\"cond_in_size\"],\n",
    "    num_cond_embs=config[\"hnet\"][\"num_cond_embs\"],\n",
    "    no_uncond_weights=False,\n",
    "    no_cond_weights=False,\n",
    ").to(config[\"device\"])\n",
    "# hnet_root.apply_chunked_hyperfan_init(mnet=hnet_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with chunking (hypernet -> hypernet -> target net)\n",
    "# def assembly_fct(list_of_chunks):\n",
    "#     assert len(list_of_chunks) == 107\n",
    "#     params_out = [\n",
    "#         list_of_chunks[0][0],\n",
    "#         list_of_chunks[1][0],\n",
    "#         list_of_chunks[2][0],\n",
    "#         list_of_chunks[0][1],\n",
    "#         list_of_chunks[2][1],\n",
    "#         list_of_chunks[1][1]\n",
    "#     ]\n",
    "#     to_concat = []\n",
    "#     for i in range(3, 52 + 3):\n",
    "#         to_concat.append(list_of_chunks[i][0])\n",
    "#     params_out.append(torch.cat(to_concat, dim=0))\n",
    "\n",
    "#     to_concat = []\n",
    "#     for i in range(52 + 3, 52 + 52 + 3):\n",
    "#         to_concat.append(list_of_chunks[i][0])\n",
    "#     params_out.append(torch.cat(to_concat, dim=0))\n",
    "    \n",
    "#     return params_out\n",
    "\n",
    "# hnet_root = StructuredHMLP(\n",
    "#     hnet_child.param_shapes,\n",
    "#     chunk_shapes=[[[8],[100]], [[100, 8], [100, 100]], [[420, 100]], [[420]]],\n",
    "#     num_per_chunk=[2, 1, 52, 52],\n",
    "#     chunk_emb_sizes=32,\n",
    "#     hmlp_kwargs=dict(layers=[100, 100]),\n",
    "#     assembly_fct=assembly_fct,\n",
    "#     uncond_in_size=0, cond_in_size=8, num_cond_embs=2).to(config[\"device\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data, solver, solver_weights, use_data_from=\"validation\"):\n",
    "    \"\"\"Compute the test accuracy for a given dataset (validation)\"\"\"\n",
    "    assert use_data_from == \"train\" or data.num_val_samples > 0, \"No validation data available.\"\n",
    "    solver_train = solver.training\n",
    "    solver.eval()\n",
    "    acc = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if use_data_from == \"validation\":\n",
    "            num_correct = 0\n",
    "\n",
    "            for batch_size, X, y, ids in data.val_iterator(config[\"data\"][\"batch_size\"], return_ids=True):\n",
    "                X = data.input_to_torch_tensor(X, config[\"device\"], mode='inference')\n",
    "                y = data.output_to_torch_tensor(y, config[\"device\"], mode='inference')\n",
    "                y_hat = solver.forward(X, weights=solver_weights)\n",
    "                num_correct += int(torch.sum(y_hat.argmax(dim=1) == y.argmax(dim=1)).detach().cpu())\n",
    "\n",
    "            acc = num_correct / data.num_val_samples * 100.\n",
    "        elif use_data_from == \"train\":\n",
    "                # Process complete test set as one batch.\n",
    "                test_in = data.input_to_torch_tensor( \\\n",
    "                    data.get_test_inputs(), config[\"device\"], mode='inference')\n",
    "                test_out = data.input_to_torch_tensor( \\\n",
    "                    data.get_test_outputs(), config[\"device\"], mode='inference')\n",
    "                test_lbls = test_out.max(dim=1)[1]\n",
    "\n",
    "                if solver_weights is not None:\n",
    "                    logits = solver(test_in, weights=solver_weights)\n",
    "                else:\n",
    "                    logits = solver(test_in)\n",
    "                pred_lbls = logits.max(dim=1)[1]\n",
    "\n",
    "                acc = torch.sum(test_lbls == pred_lbls) / test_lbls.numel() * 100.\n",
    "        else:\n",
    "            raise ValueError(\"Unknown data source (use 'train' or 'validation').\")\n",
    "\n",
    "    solver.train(mode=solver_train)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_param_shapes(solver, params):\n",
    "    \"\"\"Correct the shapes of the parameters for the solver\"\"\"\n",
    "    params_solver = []\n",
    "    src_param_i = 0\n",
    "    src_param_start_idx = 0\n",
    "\n",
    "    for target_param_i, p_shape in enumerate(solver_root.param_shapes):\n",
    "        curr_available_src_params = params[src_param_i].flatten()[src_param_start_idx:].numel()\n",
    "        if curr_available_src_params >= math.prod(p_shape):\n",
    "            params_solver.append(params[src_param_i].flatten()[src_param_start_idx:src_param_start_idx + math.prod(p_shape)].view(p_shape))\n",
    "            src_param_start_idx += math.prod(p_shape)\n",
    "        else:\n",
    "            new_param = torch.zeros(math.prod(p_shape), device=config[\"device\"])\n",
    "            s, e = 0, 0\n",
    "\n",
    "            while math.prod(p_shape) > e:\n",
    "                curr_available_src_params = params[src_param_i].flatten().numel()\n",
    "                to_add = params[src_param_i].flatten()[src_param_start_idx:min(curr_available_src_params, src_param_start_idx + (math.prod(p_shape) - e))]\n",
    "                e = s + to_add.numel()\n",
    "                new_param[s:e] = to_add\n",
    "                s += to_add.numel()\n",
    "\n",
    "                if e < math.prod(p_shape):\n",
    "                    src_param_i += 1\n",
    "                    src_param_start_idx = 0\n",
    "                else:\n",
    "                    src_param_start_idx += to_add.numel()\n",
    "\n",
    "            params_solver.append(new_param.view(p_shape))\n",
    "    return params_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_delta_theta(optimizer, lr, clip_delta=True, detach=False):\n",
    "    ret = []\n",
    "    for g in optimizer.param_groups:\n",
    "        for p in g[\"params\"]:\n",
    "            if p.grad is None:\n",
    "                ret.append(None)\n",
    "                continue\n",
    "            if detach:\n",
    "                ret.append(-lr * p.grad.detach().clone())\n",
    "            else:\n",
    "                ret.append(-lr * p.grad.clone())\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_loss_for_cond(hnet, hnet_prev_params, hnet_optimizer, lr, reg_cond_id, detach_d_theta=False):\n",
    "    # prepare targets (theta for child nets predicted by previous hnet)\n",
    "    hnet_mode = hnet.training\n",
    "    hnet.eval()\n",
    "    with torch.no_grad():\n",
    "        theta_child_target = hnet(cond_id=reg_cond_id, weights={\"uncond_weights\": hnet_prev_params} if hnet_prev_params is not None else None)\n",
    "    # detaching target below is important!\n",
    "    theta_child_target = torch.cat([p.detach().clone().view(-1) for p in theta_child_target])\n",
    "    hnet.train(mode=hnet_mode)\n",
    "    \n",
    "    d_theta = calc_delta_theta(hnet_optimizer, lr, detach=detach_d_theta)\n",
    "    theta_parent_for_pred = []\n",
    "    for _theta, _d_theta in zip(hnet.internal_params, d_theta):\n",
    "        if _d_theta is None:\n",
    "            theta_parent_for_pred.append(_theta)\n",
    "        else:\n",
    "            theta_parent_for_pred.append(_theta + _d_theta if detach_d_theta is False else _theta + _d_theta.detach())\n",
    "    theta_child_predicted = hnet(cond_id=reg_cond_id, weights=theta_parent_for_pred)\n",
    "    theta_child_predicted = torch.cat([p.view(-1) for p in theta_child_predicted])\n",
    "\n",
    "    return (theta_child_target - theta_child_predicted).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_loss(hnet, hnet_prev_params, hnet_optimizer, curr_cond_id, lr=1e-3, clip_grads_max_norm=1., detach_d_theta=False):\n",
    "    if clip_grads_max_norm is not None:\n",
    "        torch.nn.utils.clip_grad_norm_(hnet.parameters(), clip_grads_max_norm)\n",
    "    reg_loss = 0\n",
    "    for c_i in range(hnet._num_cond_embs):\n",
    "        if curr_cond_id is not None and c_i == curr_cond_id:\n",
    "            continue\n",
    "        reg_loss += get_reg_loss_for_cond(hnet, hnet_prev_params, hnet_optimizer, lr, c_i, detach_d_theta)\n",
    "    return reg_loss / (hnet._num_cond_embs - (curr_cond_id is not None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(X, scenario, hnet_root_cond_id, hnet_child_cond_id, hnet_root, hnet_child, solver_root, solver_child):\n",
    "    assert scenario != \"hnet->hnet->solver\" or hnet_child_cond_id is not None, f\"Scenario {scenario} requires hnet_child_cond_id to be set\"\n",
    "    \n",
    "    if scenario == \"hnet->solver\":\n",
    "        params_solver = hnet_root.forward(cond_id=hnet_root_cond_id) # root hnet -> params root solver\n",
    "        y_hat = solver_root.forward(X, weights=correct_param_shapes(solver_root, params_solver))\n",
    "    elif scenario == \"hnet->hnet->solver\":\n",
    "        # params_hnet_child = hnet_root.forward(cond_id=hnet_root_cond_id)[hnet_child._num_cond_embs:] # root hnet -> params child hnet (only the unconditional ones)\n",
    "        # if len(hnet_child.conditional_param_shapes) is not hnet_child._num_cond_embs:\n",
    "        #     params_hnet_child = params_hnet_child[:-(len(hnet_child.conditional_param_shapes) - hnet_child._num_cond_embs)]\n",
    "        params_hnet_child = hnet_root.forward(cond_id=hnet_root_cond_id) # root hnet -> params child hnet (only the unconditional ones)\n",
    "        params_solver = hnet_child.forward(cond_id=hnet_child_cond_id, weights=params_hnet_child)\n",
    "        y_hat = solver_child.forward(X, weights=params_solver)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown inference scenario {scenario}\")\n",
    "    return y_hat, params_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(datasets : dict, hnet_root, hnet_child, solver_root, solver_child, loss_fn, prefix=\"\", skip_phases=[]):\n",
    "    print(prefix)\n",
    "    with torch.no_grad():\n",
    "        for data_name, (hnet_root_cond_id_hnet_solver, hnet_root_cond_id_hnet_hnet_solver, hnet_child_cond_id, dataset, X, y) in datasets.items():\n",
    "            print(data_name)\n",
    "            if \"hnet->solver\" not in skip_phases:\n",
    "                print(\"    hnet->solver\")\n",
    "                y_hat, params_solver_root = infer(X, \"hnet->solver\", hnet_root_cond_id_hnet_solver, None, hnet_root, hnet_child, solver_root, solver_child)\n",
    "                loss_root = loss_fn(y_hat, y)\n",
    "                print(f\"        Loss: {loss_root.item():.3f} | Accuracy: {calc_accuracy(dataset, solver_root, correct_param_shapes(solver_root, params_solver_root)):.3f}\")\n",
    "            \n",
    "            if \"hnet->hnet->solver\" not in skip_phases:\n",
    "                print(\"    hnet->hnet->solver\")\n",
    "                y_hat, params_solver_child = infer(X, \"hnet->hnet->solver\", hnet_root_cond_id_hnet_hnet_solver, hnet_child_cond_id, hnet_root, hnet_child, solver_root, solver_child)\n",
    "                loss_child = loss_fn(y_hat, y)\n",
    "                print(f\"        Loss: {loss_child.item():.3f} | Accuracy: {calc_accuracy(dataset, solver_child, params_solver_child):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "hnet_root_optim = torch.optim.Adam(hnet_root.internal_params, lr=config[\"hnet\"][\"lr\"])\n",
    "hnet_child_optim = torch.optim.Adam(hnet_child.internal_params, lr=config[\"hnet\"][\"lr\"])\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "hnet_root_prev_phase_params = None\n",
    "\n",
    "phases = [\"hnet->solver\", \"hnet->hnet->solver\", \"hnet->solver\", \"hnet->hnet->solver\"]\n",
    "for p_i, phase in enumerate(phases):\n",
    "    print(f\"\\n\\n.... Starting phase {phase} ...\")\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        for i, ((_, m_X, m_y),(_, f_X, f_y)) in enumerate(zip(mnist.train_iterator(config[\"data\"][\"batch_size\"]), fmnist.train_iterator(config[\"data\"][\"batch_size\"]))):\n",
    "            if i > config[\"max_minibatches_per_epoch\"]:\n",
    "                break\n",
    "\n",
    "            # Mini-batch of MNIST samples\n",
    "            m_X = mnist.input_to_torch_tensor(m_X, config[\"device\"], mode=\"train\")\n",
    "            m_y = mnist.output_to_torch_tensor(m_y, config[\"device\"], mode=\"train\")\n",
    "            # Mini-batch of FashionMNIST samples\n",
    "            f_X = fmnist.input_to_torch_tensor(f_X, config[\"device\"], mode=\"train\")\n",
    "            f_y = fmnist.output_to_torch_tensor(f_y, config[\"device\"], mode=\"train\")\n",
    "\n",
    "            hnet_root_optim.zero_grad()\n",
    "            hnet_child_optim.zero_grad()\n",
    "\n",
    "            # Compute MNIST loss\n",
    "            if phase == \"hnet->solver\":\n",
    "                hnet_root_cond_id = 0\n",
    "                hnet_child_cond_id = None\n",
    "            elif phase == \"hnet->hnet->solver\":\n",
    "                hnet_root_cond_id = 2\n",
    "                hnet_child_cond_id = 0\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown phase {phase}\")\n",
    "            y_hat, _ = infer(m_X, phase, hnet_root_cond_id=hnet_root_cond_id, hnet_child_cond_id=hnet_child_cond_id, hnet_root=hnet_root, hnet_child=hnet_child, solver_root=solver_root, solver_child=solver_child)\n",
    "            m_loss = loss_fn(y_hat, m_y.max(dim=1)[1])\n",
    "            m_loss.backward(retain_graph=True)\n",
    "            # regularization against forgetting other contexts\n",
    "            m_loss_reg = get_reg_loss(hnet_root, hnet_root_prev_phase_params, hnet_root_optim, curr_cond_id=hnet_root_cond_id, lr=config[\"hnet\"][\"reg_lr\"], clip_grads_max_norm=1., detach_d_theta=False)\n",
    "            hnet_root_optim.zero_grad()\n",
    "            hnet_child_optim.zero_grad()\n",
    "\n",
    "            # Compute FashionMNIST loss\n",
    "            if phase == \"hnet->solver\":\n",
    "                hnet_root_cond_id = 1\n",
    "                hnet_child_cond_id = None\n",
    "            elif phase == \"hnet->hnet->solver\":\n",
    "                hnet_root_cond_id = 3\n",
    "                hnet_child_cond_id = 1\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown phase {phase}\")\n",
    "            y_hat, _ = infer(f_X, phase, hnet_root_cond_id=hnet_root_cond_id, hnet_child_cond_id=hnet_child_cond_id, hnet_root=hnet_root, hnet_child=hnet_child, solver_root=solver_root, solver_child=solver_child)\n",
    "            f_loss = loss_fn(y_hat, f_y.max(dim=1)[1])\n",
    "            f_loss.backward(retain_graph=True)\n",
    "            # regularization against forgetting other contexts\n",
    "            f_loss_reg = get_reg_loss(hnet_root, hnet_root_prev_phase_params, hnet_root_optim, curr_cond_id=hnet_root_cond_id, lr=config[\"hnet\"][\"reg_lr\"], clip_grads_max_norm=1., detach_d_theta=False)\n",
    "            hnet_root_optim.zero_grad()\n",
    "            hnet_child_optim.zero_grad()\n",
    "\n",
    "            total_loss = m_loss + f_loss + config[\"hnet\"][\"reg_beta\"] * m_loss_reg + config[\"hnet\"][\"reg_beta\"] * f_loss_reg\n",
    "            total_loss.backward()\n",
    "            \n",
    "            hnet_root_optim.step()\n",
    "            hnet_child_optim.step()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print_metrics(\n",
    "                    {\"MNIST\": (0, 2, 0, mnist, m_X, m_y.max(dim=1)[1]), \"FashionMNIST\": (1, 3, 1, fmnist, f_X, f_y.max(dim=1)[1])},\n",
    "                    hnet_root, hnet_child, solver_root, solver_child, loss_fn, prefix=f\"[{phase} | {epoch}/{config['epochs']} | {i + 1}]\\nM: {m_loss_reg:.2f} F: {f_loss_reg:.2f}\",\n",
    "                    skip_phases=[\"hnet->hnet->solver\"] if p_i == 0 and phase == \"hnet->solver\" else [],\n",
    "                )\n",
    "    hnet_root_prev_phase_params = [p.detach().clone() for p_idx, p in enumerate(hnet_root.unconditional_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics({\"MNIST\": (0, 2, 0, mnist, m_X, m_y.max(dim=1)[1]), \"FashionMNIST\": (1, 3, 1, fmnist, f_X, f_y.max(dim=1)[1])}, hnet_root, hnet_child, solver_root, solver_child, hnet_root_optimizer, loss_fn, prefix=f\"[{phase} | {epoch}/{config['epochs']} | {i + 1}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 98 mnist, 89 fmnist (hypernet -> target net)\n",
    "- 98 mnist, 88 fmnist (hypernet -> hypernet -> target net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('vylet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1aba0afea106d50199ec03ffaadaf3934529de3f3f9deaaa8fc5cd22ec9480e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
